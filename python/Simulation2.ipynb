{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "colab_type": "code",
    "id": "D2jKyNyKBcWu",
    "outputId": "25ad1b83-e17c-4e51-f8ff-d86490a0a230"
   },
   "outputs": [],
   "source": [
    "#!pip install shap\n",
    "#!pip install rfpimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GHdppbK2Bhz_"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import shap \n",
    "#import rfpimp\n",
    "\n",
    "import warnings\n",
    "\n",
    "import time\n",
    "\n",
    "from scipy.stats import logistic\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "brw-X0xkBi7N"
   },
   "outputs": [],
   "source": [
    "#https://github.com/parrt/random-forest-importances/blob/master/src/rfpimp.py\n",
    "def oob_regression_r2_score(rf, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Compute out-of-bag (OOB) R^2 for a scikit-learn random forest\n",
    "    regressor. We learned the guts of scikit's RF from the BSD licensed\n",
    "    code:\n",
    "    https://github.com/scikit-learn/scikit-learn/blob/a24c8b46/sklearn/ensemble/forest.py#L702\n",
    "    \"\"\"\n",
    "    X = X_train.values if isinstance(X_train, pd.DataFrame) else X_train\n",
    "    y = y_train.values if isinstance(y_train, pd.Series) else y_train\n",
    "\n",
    "    n_samples = len(X)\n",
    "    predictions = np.zeros(n_samples)\n",
    "    n_predictions = np.zeros(n_samples)\n",
    "    for tree in rf.estimators_:\n",
    "        unsampled_indices = generate_unsampled_indices(tree.random_state, n_samples)\n",
    "        tree_preds = tree.predict(X[unsampled_indices, :])\n",
    "        predictions[unsampled_indices] += tree_preds\n",
    "        n_predictions[unsampled_indices] += 1\n",
    "\n",
    "    if (n_predictions == 0).any():\n",
    "        warnings.warn(\"Too few trees; some variables do not have OOB scores.\")\n",
    "        n_predictions[n_predictions == 0] = 1\n",
    "\n",
    "    predictions /= n_predictions\n",
    "\n",
    "    oob_score = r2_score(y, predictions)\n",
    "    return oob_score\n",
    "\n",
    "#http://bakfu.github.io/doc/_modules/sklearn/ensemble/forest.html\n",
    "from sklearn.utils import check_random_state #, check_array, compute_sample_weight\n",
    "#from sklearn.utils.fixes import bincount\n",
    "\n",
    "def generate_sample_indices(random_state, n_samples):\n",
    "    \"\"\"Private function used to _parallel_build_trees function.\"\"\"\n",
    "    random_instance = check_random_state(random_state)\n",
    "    sample_indices = random_instance.randint(0, n_samples, n_samples)\n",
    "\n",
    "    return sample_indices\n",
    "\n",
    "def generate_unsampled_indices(random_state, n_samples):\n",
    "    \"\"\"Private function used to forest._set_oob_score fuction.\"\"\"\n",
    "    sample_indices = generate_sample_indices(random_state, n_samples)\n",
    "    sample_counts = np.bincount(sample_indices, minlength=n_samples)\n",
    "    unsampled_mask = sample_counts == 0\n",
    "    indices_range = np.arange(n_samples)\n",
    "    unsampled_indices = indices_range[unsampled_mask]\n",
    "\n",
    "    return unsampled_indices\n",
    "\n",
    "def shap_values_oob(X_train, rf):\n",
    "    n_samples, p = X_train.shape\n",
    "    k=0\n",
    "    shap_oob = np.zeros((n_samples, p, rf.n_estimators))\n",
    "    shap_inbag = np.zeros((n_samples, p, rf.n_estimators))\n",
    "    for tree in rf.estimators_:\n",
    "      tree_preds = tree.predict(X_train)\n",
    "      unsampled_indices = generate_unsampled_indices(tree.random_state, n_samples)\n",
    "      sampled_indices = generate_sample_indices(tree.random_state, n_samples)\n",
    "      explainer = shap.TreeExplainer(tree)\n",
    "      shap_oob[unsampled_indices,:,k] = explainer.shap_values(X_train.iloc[unsampled_indices,:])\n",
    "      shap_inbag[sampled_indices,:,k] = explainer.shap_values(X_train.iloc[sampled_indices,:])\n",
    "      #print(k)\n",
    "      k+=1\n",
    "    \n",
    "    shap_oob_avg = np.sum(shap_oob, axis=2) \n",
    "    shap_inbag_avg = np.sum(shap_inbag, axis=2)\n",
    "    globalSHAPImp_oob =np.sum(np.abs(shap_oob_avg), axis=0)\n",
    "    globalSHAPImp_inbag = np.sum(np.abs(shap_inbag_avg), axis=0)\n",
    "    return shap_oob,shap_inbag,shap_oob_avg,shap_inbag_avg,globalSHAPImp_oob,globalSHAPImp_inbag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NoisyFeatureIdentification(N=1000, # number of rows in data\n",
    "                        p=50, # number of features\n",
    "                        #nCores = M, # number of cores to use; set to 1 on Windows!\n",
    "                        relevance = 0.15, # signal srength (0 for NULL)\n",
    "                        inoutbag=False,\n",
    "                        ntree = 100, #number of trees in forest\n",
    "                        #correctBias = c(inbag=TRUE,outbag=TRUE),\n",
    "                        verbose=0,\n",
    "                        n_features = 2):\n",
    "  \n",
    "  #VERY dangerous to put this into the function\n",
    "  #random.seed(123)\n",
    "\n",
    "  shap_avs = np.array([0,0,0,0,0]) # Initializes the first array\n",
    "  ft_importances = np.array([0,0,0,0,0]) # Initializes the first array\n",
    "  shap_vals = np.array([0,0,0,0,0]) # Initializes the first array\n",
    "  allDFs = [] # List of DFs that will be filled\n",
    "\n",
    "\n",
    "  allXs = []\n",
    "\n",
    "  for i in range(p):\n",
    "    allXs.append([np.random.randint(0, i+2, N)])#i+2\n",
    "  \n",
    "  rlvFtrs = np.array([0] * p)\n",
    "  # rlvFtrs[np.random.randint(1, 11, 5)] = 1\n",
    "  rlvFtrs[np.random.choice(range(0, 10), 5, replace=False)] = 1\n",
    "  position = np.where(rlvFtrs == 1)[0]\n",
    "\n",
    "  Xrlv = np.array([0]*N) \n",
    "\n",
    "  for k in (np.where(rlvFtrs == 1)[0]):\n",
    "    Xrlv = Xrlv + allXs[k]/(k+1)\n",
    "\n",
    "  y = np.array([]) \n",
    "\n",
    "  for i in range(N):\n",
    "    y = np.append(y, np.random.binomial(n = 1, p = logistic.cdf(2*Xrlv[0][i]/5 - 1), size = 1))\n",
    "\n",
    "  x_train = pd.DataFrame(np.concatenate(allXs).T.reshape(N, p, order='F')) \n",
    "\n",
    "\n",
    "  rf = RandomForestRegressor(max_depth=50, random_state=0, n_estimators=ntree,max_features=n_features) \n",
    "  rf.fit(x_train, y)\n",
    "  feature_importances = rf.feature_importances_\n",
    "  #imp = permutation_importances(rf, X_train, y,oob_regression_r2_score)\n",
    "  # print(feature_importances)\n",
    "  \n",
    "  warnings.filterwarnings('ignore')\n",
    "  if (inoutbag):\n",
    "    shap_oob,shap_inbag,shap_oob_avg,shap_inbag_avg,globalSHAPImp_oob,globalSHAPImp_inbag = shap_values_oob(x_train, rf)\n",
    "    return(shap_oob,shap_inbag,shap_oob_avg,shap_inbag_avg,globalSHAPImp_oob,globalSHAPImp_inbag, rlvFtrs,y)\n",
    "  else:\n",
    "    shap_values = shap.TreeExplainer(rf, feature_perturbation=\"tree_path_dependent\" ).shap_values(x_train)\n",
    "    #shap_values = shap.TreeExplainer(rf).shap_values(x_train)\n",
    "    shap_averages = np.sum(np.absolute(shap_values), axis=0)\n",
    "    return(shap_values, shap_averages, feature_importances, x_train, rlvFtrs)\n",
    "    \n",
    "\n",
    "  '''\n",
    "  shap_vals = np.vstack((shap_vals, shap_values))\n",
    "  shap_avs = np.vstack((shap_avs, shap_averages))\n",
    "  ft_importances = np.vstack((ft_importances, feature_importances))\n",
    "  allDFs.append(x_train)\n",
    "  \n",
    "  shap_vals = np.delete(shap_vals, (0), axis=0) # Deletes the initialization\n",
    "  shap_avs = np.delete(shap_avs, (0), axis=0) # Deletes the initialization\n",
    "  ft_importances = np.delete(ft_importances, (0), axis=0) # Deletes the initialization\n",
    "  '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hnpgGI2wyqPh",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with iteration 0\n",
      "done with iteration 1\n",
      "done with iteration 2\n",
      "done with iteration 3\n",
      "done with iteration 4\n",
      "done with iteration 5\n",
      "done with iteration 6\n",
      "done with iteration 7\n",
      "done with iteration 8\n",
      "done with iteration 9\n",
      "done with iteration 10\n",
      "done with iteration 11\n",
      "done with iteration 12\n",
      "done with iteration 13\n",
      "done with iteration 14\n",
      "done with iteration 15\n",
      "done with iteration 16\n",
      "done with iteration 17\n",
      "done with iteration 18\n",
      "done with iteration 19\n",
      "done with iteration 20\n",
      "done with iteration 21\n",
      "done with iteration 22\n",
      "done with iteration 23\n",
      "done with iteration 24\n",
      "done with iteration 25\n",
      "done with iteration 26\n",
      "done with iteration 27\n",
      "done with iteration 28\n",
      "done with iteration 29\n",
      "done with iteration 30\n",
      "done with iteration 31\n",
      "done with iteration 32\n",
      "done with iteration 33\n",
      "done with iteration 34\n",
      "done with iteration 35\n",
      "done with iteration 36\n",
      "done with iteration 37\n",
      "done with iteration 38\n",
      "done with iteration 39\n",
      "done with iteration 40\n",
      "done with iteration 41\n",
      "done with iteration 42\n",
      "done with iteration 43\n",
      "done with iteration 44\n",
      "done with iteration 45\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "random.seed(123)\n",
    "N=1000;p0=50\n",
    "\n",
    "shap_oob, shap_inbag, shap_oob_all, shap_inbag_all, globalSHAPImp_oob, globalSHAPImp_inbag, rlvFtrs_all, y_train_all = NoisyFeatureIdentification(N=N, p=p0, inoutbag=True)\n",
    "#shap_oob_all=globalSHAPImp_oob\n",
    "#shap_inbag_all=globalSHAPImp_inbag\n",
    "nSims = 50\n",
    "\n",
    "for i in range(nSims-1):\n",
    "\n",
    "    shap_oob, shap_inbag, shap_oob_avg, shap_inbag_avg, globalSHAPImp_oob, globalSHAPImp_inbag, rlvFtrs, y_train = NoisyFeatureIdentification(N=N, p=p0, inoutbag=True)\n",
    "    print(\"done with iteration\", i)\n",
    "    \n",
    "    shap_oob_all = np.vstack((shap_oob_all, shap_oob_avg))\n",
    "    shap_inbag_all = np.vstack((shap_inbag_all, shap_inbag_avg))\n",
    "    #shap_oob_all = np.vstack((shap_oob_all, globalSHAPImp_oob))\n",
    "    #shap_inbag_all = np.vstack((shap_inbag_all, globalSHAPImp_inbag))\n",
    "    rlvFtrs_all = np.hstack((rlvFtrs_all,rlvFtrs))\n",
    "    y_train_all = np.hstack((y_train_all,y_train))\n",
    "\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap_averages_oob = np.sum(np.absolute(), axis=0) \n",
    "\n",
    "#shap_oob, shap_inbag, shap_oob_all, shap_inbag_all, globalSHAPImp_oob, globalSHAPImp_inbag, rlvFtrs_all = NoisyFeatureIdentification(N=100, p=10, inoutbag=True)\n",
    "#shap_oob, shap_inbag, shap_oob_avg, shap_inbag_avg, globalSHAPImp_oob, globalSHAPImp_inbag, rlvFtrs = NoisyFeatureIdentification(N=100, p=10, inoutbag=True)\n",
    "rlvFtrs_all.tofile(\"data/rlvFtrs_all.tsv\",\"\\t\")\n",
    "shap_oob_all.tofile(\"data/shap_oob_all.tsv\",\"\\t\")\n",
    "shap_inbag_all.tofile(\"data/shap_inbag_all.tsv\",\"\\t\")\n",
    "y_train_all.tofile(\"data/y_train_all.tsv\",\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 50) (50000, 50)\n"
     ]
    }
   ],
   "source": [
    "shap_oob_all_wghted = (shap_oob_all.T*y_train_all).T\n",
    "shap_inbag_all_wghted = (shap_inbag_all.T*y_train_all).T\n",
    "\n",
    "print(shap_inbag_all_wghted.shape,shap_oob_all_wghted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,) (50,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 50)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=-1\n",
    "shap_oob_all_wghted_avg =  np.sum(np.absolute(shap_oob_all_wghted[np.arange(N*(i+1),N*(i+2)),:]), axis=0) \n",
    "shap_inbag_all_wghted_avg =  np.sum(np.absolute(shap_inbag_all_wghted[np.arange(N*(i+1),N*(i+2)),:]), axis=0) \n",
    "print(shap_oob_all_wghted_avg.shape, shap_inbag_all_wghted_avg.shape)\n",
    "np.vstack((shap_oob_all_wghted_avg,shap_inbag_all_wghted_avg)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,) (50,)\n",
      "(50, 50) (50, 50) (2500,)\n"
     ]
    }
   ],
   "source": [
    "#rlvFtrs_all = np.hstack((rlvFtrs_all,rlvFtrs))\n",
    "i=-1\n",
    "shap_oob_all_wghted_avg =  np.sum(np.absolute(shap_oob_all_wghted[np.arange(N*(i+1),N*(i+2)),:]), axis=0) \n",
    "shap_inbag_all_wghted_avg =  np.sum(np.absolute(shap_inbag_all_wghted[np.arange(N*(i+1),N*(i+2)),:]), axis=0) \n",
    "print(shap_oob_all_wghted_avg.shape,shap_inbag_all_wghted_avg.shape)\n",
    "\n",
    "for i in range(nSims-1):\n",
    "    tmp = np.sum(np.absolute(shap_oob_all_wghted[np.arange(N*(i+1),N*(i+2)),:]), axis=0)\n",
    "    shap_oob_all_wghted_avg = np.vstack((shap_oob_all_wghted_avg, tmp ))\n",
    "    tmp = np.sum(np.absolute(shap_inbag_all_wghted[np.arange(N*(i+1),N*(i+2)),:]), axis=0) \n",
    "    shap_inbag_all_wghted_avg = np.vstack((shap_inbag_all_wghted_avg, tmp ))\n",
    "\n",
    "print(shap_oob_all_wghted_avg.shape,shap_inbag_all_wghted_avg.shape,rlvFtrs_all.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500,) (2500,) (2500,)\n",
      "oob 0.7247822222222221\n",
      "inbag 0.5603946666666666\n"
     ]
    }
   ],
   "source": [
    "rlvFtrs_oneArray = rlvFtrs_all #np.concatenate(rlvFtrs)\n",
    "shap_oob_avg_oneArray = np.concatenate(shap_oob_all_wghted_avg)#shap_oob_all)\n",
    "shap_inbag_avg_oneArray = np.concatenate(shap_inbag_all_wghted_avg)#shap_inbag_all)\n",
    "print(rlvFtrs_oneArray.shape, shap_oob_avg_oneArray.shape, shap_inbag_avg_oneArray.shape)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(rlvFtrs_oneArray, shap_oob_avg_oneArray)\n",
    "print(\"oob\", metrics.auc(fpr, tpr))\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(rlvFtrs_oneArray, shap_inbag_avg_oneArray)\n",
    "print(\"inbag\", metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 50)\n",
      "(2500,) (50000, 50) (50000, 50) (50000,)\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "print(shap_oob_avg.shape)\n",
    "print(rlvFtrs_all.shape, shap_oob_all.shape, shap_inbag_all.shape, y_train_all.shape)\n",
    "#print(rlvFtrs_all.shape, shap_oob_all.shape, shap_inbag_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500,) (2500000,) (2500000,)\n"
     ]
    }
   ],
   "source": [
    "#shap_inbag_avg.append(fourth)\n",
    "#rlvFtrs.append(seventh)\n",
    "rlvFtrs_oneArray = rlvFtrs_all #np.concatenate(rlvFtrs)\n",
    "shap_oob_avg_oneArray = np.concatenate(shap_oob_all_wghted)#shap_oob_all)\n",
    "shap_inbag_avg_oneArray = np.concatenate(shap_inbag_all_wghted)#shap_inbag_all)\n",
    "print(rlvFtrs_oneArray.shape, shap_oob_avg_oneArray.shape, shap_inbag_avg_oneArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oob 0.6949937777777778\n",
      "inbag 0.5164213333333334\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(rlvFtrs_oneArray, shap_oob_avg_oneArray)\n",
    "print(\"oob\", metrics.auc(fpr, tpr))\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(rlvFtrs_oneArray, shap_inbag_avg_oneArray)\n",
    "print(\"inbag\", metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wLSfBmkfO9mk",
    "outputId": "33bd4870-7118-4a08-d92f-68609b5520cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1120.602492570877 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "random.seed(123)\n",
    "\n",
    "shap_vals, shap_avs, ft_importances, x_train, rlvFtrs = ([] for i in range(5))\n",
    "nSims = 100\n",
    "\n",
    "for i in range(nSims):\n",
    "\n",
    "  first, second, third, fourth, fifth = NoisyFeatureIdentification(N=1000, p=50)\n",
    "  print(\"done with iteration\" % i)\n",
    "  shap_vals.append(first)\n",
    "  shap_avs.append(second)\n",
    "  ft_importances.append(third)\n",
    "  x_train.append(fourth)\n",
    "  rlvFtrs.append(fifth)\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "W0CL1ngZRQjR",
    "outputId": "2773fdff-c5b7-4c39-e5df-e1e8ba471f8c"
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "irgzAg4cXX6u",
    "outputId": "bf796a5a-77eb-48f6-d7ad-1b7df33d4e9f"
   },
   "outputs": [],
   "source": [
    "plt.boxplot(shap_avs[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "Vtjs8IoYXYB2",
    "outputId": "2e002eac-0324-4300-ab4f-fed027422cbf"
   },
   "outputs": [],
   "source": [
    "plt.boxplot(ft_importances);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9xO1e8qziweh"
   },
   "outputs": [],
   "source": [
    "# save with pickle\n",
    "import pickle\n",
    "pickle.dump(shap_avs, open(\"shap_avs.p\", \"wb\"))\n",
    "pickle.dump(rlvFtrs, open(\"rlvFtrs.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "WK21fHJZiyjB",
    "outputId": "743d6add-65fa-4440-eef5-d081609108e4"
   },
   "outputs": [],
   "source": [
    "# load with pickle\n",
    "import pickle\n",
    "shap_avs2 = pickle.load(open(\"shap_avs.p\", \"rb\"))\n",
    "rlvFtrs2 = pickle.load(open(\"rlvFtrs.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n",
      "(5000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlvFtrs_oneArray = np.concatenate(rlvFtrs2)\n",
    "shap_avs_oneArray2 = np.concatenate(shap_avs2)\n",
    "print(rlvFtrs_oneArray.shape)\n",
    "print(shap_avs_oneArray2.shape)\n",
    "len(shap_avs2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OnNGiSXjXbtz",
    "outputId": "4d440036-c01d-4b4c-eac7-5d9b8a283c88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6576973333333334"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlvFtrs_oneArray = np.concatenate(rlvFtrs)\n",
    "shap_avs_oneArray = np.concatenate(shap_avs)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(rlvFtrs_oneArray, shap_avs_oneArray)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nUD0Fcp0XKEk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "87vTeuYjYOLo"
   },
   "outputs": [],
   "source": [
    "## Test von x_train ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "oPqwVD94VgB-",
    "outputId": "cddb1366-1ba9-41ef-a429-9ac67e740b21"
   },
   "outputs": [],
   "source": [
    "allXs = []\n",
    "\n",
    "for i in range(p):\n",
    "    allXs.append([np.random.randint(0, i+2, N)])#i+2\n",
    "\n",
    "pd.DataFrame(np.concatenate(allXs).reshape(N, p, order='F')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AKsvi7ht40zl"
   },
   "outputs": [],
   "source": [
    "allXs2 = []\n",
    "N = 10\n",
    "p = 4\n",
    "\n",
    "for i in range(p):\n",
    "  allXs2.append([np.arange(1+i*N,1+N+i*N)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HxW2ymQdVUt5",
    "outputId": "859ecdc0-0f0e-4cbc-db4c-4493c7445a6e"
   },
   "outputs": [],
   "source": [
    "allXs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "wEMTOEF_V8S8",
    "outputId": "305d37cc-941d-46be-d122-d386a85367d9"
   },
   "outputs": [],
   "source": [
    "allXs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "Ve4ap01nWIQe",
    "outputId": "25bca5ca-5141-422b-efab-5601012eba88"
   },
   "outputs": [],
   "source": [
    "np.concatenate(allXs2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "PzNCTityVVRU",
    "outputId": "5d87c077-3102-44fc-da13-3ed970596041"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(np.concatenate(allXs2).T.reshape(N, p, order = \"F\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlnDWTGVVY69"
   },
   "outputs": [],
   "source": [
    "## ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "colab_type": "code",
    "id": "Dt32nyz2xcPM",
    "outputId": "4343caf4-9f9c-4639-8f0d-15185cbbb3b6"
   },
   "outputs": [],
   "source": [
    "#explorations:\n",
    "allXs = []\n",
    "\n",
    "for i in range(8):\n",
    "  allXs.append([np.random.randint(0, i+2, 100)])\n",
    "\n",
    "y= np.random.binomial(n = 1, p = ==0.5, size = 100)\n",
    "x_train = pd.DataFrame(np.concatenate(allXs).reshape(100, 8, order='F'))\n",
    "x_train.shape\n",
    "\n",
    "rf = RandomForestRegressor(max_depth=50, random_state=0, n_estimators=50,max_features=2) \n",
    "rf.fit(x_train, y)\n",
    "\n",
    "#imp =  rfpimp.importances(rf, x_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gP2quMDWxT8V"
   },
   "outputs": [],
   "source": [
    "shap_vals, shap_avs, ft_importances, x_train, rlvFtrs = SimulateData_simple(n_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "5r2WXTsMB9RZ",
    "outputId": "c1014d28-5b1e-4b05-d74d-6f8ebcf9fbd2"
   },
   "outputs": [],
   "source": [
    "print(ft_importances[np.where(rlvFtrs == 1)[0]])\n",
    "print(ft_importances[np.where(rlvFtrs == 0)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "xxbKL-PqCMaa",
    "outputId": "2f97bbdb-fe94-4197-b30d-a88efe44507f"
   },
   "outputs": [],
   "source": [
    "#shap_avs.shape\n",
    "rlvFtrs\n",
    "shap.summary_plot(shap_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lpl0yXak9kOf",
    "outputId": "a74e6425-191e-4cf3-f289-a61779fca8f9"
   },
   "outputs": [],
   "source": [
    "#shap_avs.shape  #[np.where(rlvFtrs == 1)[0]]\n",
    "#shap_vals.shape\n",
    "#tmp= np.sum(np.absolute(shap_vals), axis=1)\n",
    "#tmp.shape\n",
    "shap.summary_plot(shap_vals, plot_type=\"bar\",max_display=50)\n",
    "np.where(rlvFtrs == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGiMcwmNYSdA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "R2Python-Simulation2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
